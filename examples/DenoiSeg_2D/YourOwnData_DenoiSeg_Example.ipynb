{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenoiSeg Example: Example Flywing data\n",
    "This is an example notebook which illustrates how DenoiSeg should be trained. In this notebook we use a membrane labeled developing Fly Wing dataset from our collaborators. This notebook can be used as a reference to train DenoiSeg networks on your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we are just importing some libraries which are needed to run this notebook.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "from denoiseg.models import DenoiSeg, DenoiSegConfig\n",
    "from denoiseg.utils.misc_utils import combine_train_test_data, shuffle_train_data, augment_data\n",
    "from denoiseg.utils.seg_utils import *\n",
    "from denoiseg.utils.compute_precision_threshold import measure_precision, compute_labels\n",
    "from denoiseg.utils.denoiseg_data_preprocessing import generate_patches_from_list\n",
    "\n",
    "from csbdeep.utils import plot_history\n",
    "from tifffile import imread, imsave\n",
    "from glob import glob\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and  Data Loading\n",
    "We download a dataset consisting of noisy flywing images. The downloaded data creates a folder `MyData` and extracts within it three subfolders `train`, `val` and `test`. These folders have subfolders `raw` and `gt`. In `train/raw` folder, there are `1428` raw images and only the first `5` of raw images have ground truth annotations in folder `train/gt`. Similarly, in `val/raw` folder, there are `252` raw images and only the first `2` of raw images have ground truth annotations in folder `val/gt`. The `test` folder only has `raw` subfolder since these are the images we want denoised and segmented outputs for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder for our data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "link = 'https://owncloud.mpi-cbg.de/index.php/s/9ok6q1azniMJobq/download'\n",
    "\n",
    "# check if data has been downloaded already\n",
    "zipPath=\"data/MyData.zip\"\n",
    "if not os.path.exists(zipPath):\n",
    "    #download and unzip data\n",
    "    data = urllib.request.urlretrieve(link, zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the training images\n",
    "train_images = imread(sorted(glob(\"data/MyData/train/raw/*.tif\")))\n",
    "val_images = imread(sorted(glob(\"data/MyData/val/raw/*.tif\")))\n",
    "test_images = imread(sorted(glob(\"data/MyData/test/raw/*.tif\")))\n",
    "available_train_masks = imread(sorted(glob(\"data/MyData/train/gt/*.tif\")))\n",
    "available_val_masks = imread(sorted(glob(\"data/MyData/val/gt/*.tif\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create zero images for missing masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create zero images for those training and validation images for which segmentation masks are not present. Then we use these zero images along with the images for which segmentation annotations are available for training the DenoiSeg network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_images_train = np.zeros((train_images.shape[0]-available_train_masks.shape[0], available_train_masks.shape[1], available_train_masks.shape[2]))\n",
    "blank_images_val = np.zeros((val_images.shape[0]-available_val_masks.shape[0], available_val_masks.shape[1], available_val_masks.shape[2]))\n",
    "blank_images_train = blank_images_train.astype(\"uint16\")\n",
    "blank_images_val = blank_images_val.astype(\"uint16\")\n",
    "\n",
    "train_masks = np.concatenate((available_train_masks,blank_images_train), axis = 0)\n",
    "val_masks = np.concatenate((available_val_masks,blank_images_val), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We do some necessary data preprocessing in the cell below such as augmenting training data; extracting foreground, background and border classes from our training and validation masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we generate patches from images and apply augmentation\n",
    "X_final, Y_final = generate_patches_from_list([X_frac], [Y_frac], augment=True, shuffle=False, shape=(128, 128))\n",
    "X_val_final, Y_val_final = generate_patches_from_list([val_images], [val_masks], augment=False, shape=(128, 128))\n",
    "\n",
    "# Here we add the channel dimension to our input images.\n",
    "# Dimensionality for training has to be 'SYXC' (Sample, Y-Dimension, X-Dimension, Channel)\n",
    "X_final = X_final[... ,np.newaxis]\n",
    "Y_final = convert_to_oneHot(Y_final, n_classes=3)\n",
    "\n",
    "X_val_final = X_val_final[... ,np.newaxis]\n",
    "Y_val_final = convert_to_oneHot(Y_val_final, n_classes=3)\n",
    "\n",
    "print(\"Shape of X:     {}\".format(X_final.shape))\n",
    "print(\"Shape of Y:     {}\".format(Y_final.shape))\n",
    "print(\"Shape of X_val: {}\".format(X_val_final.shape))\n",
    "print(\"Shape of Y_val: {}\".format(Y_val_final.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at a single sample. In the first column we show the input image, in the second column the background segmentation, in the third column the foreground segmentation and in the last column the border segmentation.\n",
    "\n",
    "With the parameter `sample` you can choose different training patches. You will notice that not all of them have a segmentation ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_final[sample,...,0])\n",
    "plt.axis('off')\n",
    "plt.title('Raw training image')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(Y_final[sample,...,0], vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('1-hot encoded background')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(Y_final[sample,...,1], vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('1-hot encoded foreground')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(Y_final[sample,...,2], vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('1-hot encoded border')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 128\n",
    "train_steps_per_epoch = min(400, max(int(X_final.shape[0]/train_batch_size), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In the next cell, you can choose how much relative importance (weight) to assign to denoising \n",
    "### and segmentation tasks by choosing appropriate value for denoiseg_alpha (between 0 and 1; with 0 being\n",
    "### only segmentation and 1 being only denoising. Here we choose denoiseg_alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DenoiSegConfig(X_final, unet_kern_size=3, n_channel_in=1, n_channel_out=4, relative_weights = [1.0,1.0,5.0],\n",
    "                      train_steps_per_epoch=train_steps_per_epoch, train_epochs=120, \n",
    "                      batch_norm=True, train_batch_size=128, unet_n_first = 32, \n",
    "                      unet_n_depth=4, denoiseg_alpha=0.5, train_tensorboard=False)\n",
    "\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'DenoiSeg_Practicalfinal_n20'\n",
    "basedir = 'models'\n",
    "model = DenoiSeg(conf, model_name, basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.train(X_final, Y_final, (X_val_final, Y_val_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(history, ['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Threshold Value\n",
    "The network predicts 4 output channels:\n",
    "1. The denoised input.\n",
    "2. The foreground likelihoods.\n",
    "3. The background likelihoods.\n",
    "4. The border likelihoods.\n",
    "\n",
    "We will threshold the foreground prediction image to obtain object segmentations. The optimal threshold is determined on the validation data. Additionally we can optimize the threshold for a given measure. In this case we choose the Average Precision (AP) measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, val_score = model.optimize_thresholds(val_images[:available_val_masks.shape[0]].astype(np.float32), val_masks, measure=measure_precision(), axes='YX')\n",
    "\n",
    "print(\"The higest score of {} is achieved with threshold = {}.\".format(np.round(val_score, 3), threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "Finally we load the test data and run the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_images = []\n",
    "segmented_images = []\n",
    "\n",
    "for i in range(test_images.shape[0]):\n",
    "    predicted_channels = model.predict(test_images[i].astype(np.float32), axes='YX')\n",
    "    denoised_images.append(predicted_channels[...,0])\n",
    "    segmented_images.append(compute_labels(predicted_channels, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sl = 6\n",
    "fig = plt.figure()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(test_images[sl])\n",
    "plt.title(\"Raw image\")\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(denoised_images[sl])\n",
    "plt.title(\"Predicted denoised image\")\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(segmented_images[sl], cmap = \"viridis\")\n",
    "plt.title(\"Predicted segmentation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export your model for Fiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_TF(name='DenoiSeg - YourOwnData Example', \n",
    "                description='This is the 2D DenoiSeg example trained on YourOwnData in python.', \n",
    "                authors=[\"You\"],\n",
    "                test_img=X_val[0,...,0], axes='YX',\n",
    "                patch_shape=(128, 128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
